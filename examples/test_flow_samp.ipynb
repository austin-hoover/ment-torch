{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7928682d-bec5-4977-a16e-4ed693f7fd80",
   "metadata": {},
   "source": [
    "## Test flow-based sampling using reverse KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b5796-2859-4a47-8f50-1a066d8cc0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import zuko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6195f-597b-42d2-9f75-8d6c36cb8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"style.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d0d814-7e85-4f64-8fcf-3f5ce37dcf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_flow(ndim: int, transforms: int = 3, depth: int = 2, width: int = 64) -> zuko.flows.Flow:\n",
    "    hidden_features = [width] * depth\n",
    "    flow = zuko.flows.NSF(features=ndim, transforms=transforms, hidden_features=hidden_features)\n",
    "    flow = zuko.flows.Flow(flow.transform.inv, flow.base)  # fast sampling\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249efd3e-78e5-4471-930b-6dbaf31206b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovNormalizer:\n",
    "    def __init__(self, cov_matrix: torch.Tensor) -> None:\n",
    "        self.cov_matrix = cov_matrix\n",
    "        self.unnorm_matrix = torch.linalg.cholesky(self.cov_matrix)\n",
    "        self.norm_matrix = torch.linalg.inv(self.unnorm_matrix)\n",
    "        \n",
    "    def unnormalize(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.matmul(x, self.unnorm_matrix.T)\n",
    "\n",
    "    def normalize(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.matmul(x, self.norm_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db793ee1-c3f9-4cf2-9c9e-98a056cbd917",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    def __init__(self, ndim: int, verbose: int = 0) -> None:\n",
    "        self.ndim = ndim\n",
    "        self.verbose = verbose\n",
    "        self.prob_func = None\n",
    "\n",
    "    def __call__(self, prob_func: torch.Tensor) -> torch.Tensor:\n",
    "        raise NotImplementedError        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd67a4-6c7d-4557-ad0a-438a0a7f92fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowSampler(Sampler):\n",
    "    def __init__(self, ndim: int, flow: zuko.flows.Flow, unnorm_matrix: torch.Tensor = None, train_kws: dict = None) -> None:\n",
    "        super().__init__(ndim=ndim)\n",
    "        \n",
    "        self.flow = flow\n",
    "        self.trained = False\n",
    "        \n",
    "        self.unnorm_matrix = unnorm_matrix\n",
    "        if self.unnorm_matrix is None:\n",
    "            self.unnorm_matrix = torch.eye(ndim)   \n",
    "\n",
    "        self.train_kws = train_kws\n",
    "        if self.train_kws is None:\n",
    "            self.train_kws = {}\n",
    "\n",
    "        self.train_kws.setdefault(\"batch_size\", 512)\n",
    "        self.train_kws.setdefault(\"iters\", 1000)\n",
    "        self.train_kws.setdefault(\"lr\", 0.001)\n",
    "        self.train_kws.setdefault(\"lr_min\", 0.001)\n",
    "        self.train_kws.setdefault(\"lr_decay\", 0.99)\n",
    "        self.train_kws.setdefault(\"print_freq\", 100)\n",
    "        self.train_kws.setdefault(\"verbose\", 0)\n",
    "\n",
    "        self.train_history = {}\n",
    "        self.train_history[\"loss\"] = []\n",
    "        self.train_history[\"time\"] = []\n",
    "\n",
    "    def unnormalize(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.matmul(z, self.unnorm_matrix.T)\n",
    "        \n",
    "    def train(self, prob_func: Callable) -> dict:\n",
    "        self.prob_func = prob_func\n",
    "\n",
    "        self.train_history = {}\n",
    "        self.train_history[\"loss\"] = []\n",
    "        self.train_history[\"time\"] = []\n",
    "\n",
    "        self.trained = True\n",
    "\n",
    "        iters = self.train_kws[\"iters\"]\n",
    "        batch_size = self.train_kws[\"batch_size\"]\n",
    "        lr = self.train_kws[\"lr\"]\n",
    "        lr_min = self.train_kws[\"lr_min\"]\n",
    "        lr_decay = self.train_kws[\"lr_decay\"]\n",
    "        print_freq = self.train_kws[\"print_freq\"]\n",
    "        verbose = self.train_kws[\"verbose\"]\n",
    "    \n",
    "        start_time = time.time()\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.flow.parameters(), lr=lr)\n",
    "        for iteration in range(iters):\n",
    "            x, log_prob = self.flow().rsample_and_log_prob((batch_size,)) \n",
    "            x = self.unnormalize(x)\n",
    "\n",
    "            loss = torch.mean(log_prob) - torch.mean(torch.log(prob_func(x) + 1.00e-15))\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # Update learning rate\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = max(lr_min, lr_decay * param_group[\"lr\"])\n",
    "    \n",
    "            # Append to history array\n",
    "            self.train_history[\"loss\"].append(loss.detach())\n",
    "            self.train_history[\"time\"].append(time.time() - start_time)\n",
    "    \n",
    "            # Print update\n",
    "            if verbose and (iteration % print_freq == 0):\n",
    "                print(iteration, loss)\n",
    "        \n",
    "        return self.train_history\n",
    "\n",
    "    def __call__(self, prob_func: Callable, size: int) -> torch.Tensor:\n",
    "        if not (prob_func is self.prob_func):\n",
    "            self.trained = False\n",
    "            \n",
    "        if not self.trained:\n",
    "            self.train(prob_func)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x = self.flow().sample((size,))\n",
    "            x = self.unnormalize(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459df015-e2fc-4396-9a3b-b91fdbc36241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_func(x: torch.Tensor) -> torch.Tensor:\n",
    "    x1 = x[..., 0]\n",
    "    x2 = x[..., 1]\n",
    "    log_prob = torch.sin(torch.pi * x1) - 2.0 * (x1**2 + x2**2 - 2.0)**2\n",
    "    return torch.exp(log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c6a090-9f00-44b7-b81d-7d7e908fb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 2\n",
    "cov_matrix = torch.eye(ndim) * (1.0 ** 2)\n",
    "normalizer = CovNormalizer(cov_matrix)\n",
    "unnorm_matrix = normalizer.unnorm_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5171ea-6d6e-413f-90e9-2f61d708e5dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flow = make_flow(ndim=ndim)\n",
    "sampler = FlowSampler(\n",
    "    ndim=ndim, \n",
    "    flow=flow, \n",
    "    unnorm_matrix=unnorm_matrix, \n",
    "    train_kws=dict(\n",
    "        iters=500,\n",
    "    )\n",
    ")\n",
    "sampler.train(prob_func);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29022223-7ed5-47b5-a855-8a67ebab983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3, 2))\n",
    "ax.plot(sampler.train_history[\"loss\"])\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce7c97a-d385-433c-935f-dd55c598dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sampler(prob_func, 100_000)\n",
    "\n",
    "bins = 64\n",
    "xmax = 3.0\n",
    "\n",
    "grid_edges = 2 * [torch.linspace(-xmax, xmax, bins)]\n",
    "grid_points = torch.stack(torch.meshgrid(*grid_edges, indexing=\"ij\"), axis=-1)\n",
    "grid_values = prob_func(grid_points)\n",
    "grid_values = grid_values.reshape((bins, bins))\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, sharex=True, sharey=True, figsize=(4.5, 2))\n",
    "axs[0].hist2d(x[:, 0], x[:, 1], bins=grid_edges)\n",
    "axs[1].pcolormesh(grid_edges[0], grid_edges[0], grid_values.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50963c11-eb75-451d-bcb7-0d39cdf3a481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ment-torch]",
   "language": "python",
   "name": "conda-env-ment-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
